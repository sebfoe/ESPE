{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer Perceptron\n",
    "\n",
    "<ol>\n",
    "    <li> Components: Input layer, Hidden layer(s) and Output layer. </li>\n",
    "    <li> Fully connected </li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps:\n",
    "\n",
    "For every epoch,\n",
    "\n",
    "<ol>\n",
    "    <li> Training data is propagated to the MLP through input layers. It passes through the hidden layers, if any forwarding outputs of activation functions to the next layer. Finally the output is generated at the output layer by applying activation functions. </li>\n",
    "    <li> The predicted output will be compared with actual output and hence error will be calculated. </li>\n",
    "    <li> If error>0, apply backpropagation methodology to modify weights starting from output layer moving towards input layer. </li>\n",
    "    <li> Check accuracy score. If satisfied, stop. Else, go to step 1. </li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class  jan_ca   jan_b  jan_g  jan_r  jan_r1  jan_r2  jan_r3    jan_n  \\\n",
      "0      1    2.00   56.50  122.5  211.0  444.00  1253.5  1462.0  1678.00   \n",
      "1      1  303.00  368.25  357.5  374.0  717.00  1101.0  1308.0  1699.00   \n",
      "2      1  511.25  252.50  254.5  388.0  643.25  1104.0  1309.0  1688.00   \n",
      "3      1   53.50   51.00  102.0  117.0  358.00  1221.0  1525.0  1795.50   \n",
      "4      1  279.00  180.00  258.0  274.5  507.00  1258.0  1524.0  1668.25   \n",
      "\n",
      "   jan_nn  ...  dec_TCG_GSO   dec_TCG   dec_LAI  dec_SAVI  dec_MSAVI  \\\n",
      "0  1815.5  ...    -0.059647  0.045820  0.717313  0.186339   0.153891   \n",
      "1  1700.0  ...    -0.109955  0.047009  0.809818  0.187611   0.164786   \n",
      "2  1639.0  ...    -0.025636  0.084585  0.827439  0.256545   0.216626   \n",
      "3  1813.0  ...    -0.438328  0.039137  1.154730  0.222647   0.216470   \n",
      "4  1761.0  ...    -0.029993  0.134382  1.425100  0.365924   0.339766   \n",
      "\n",
      "    dec_BUI  dec_NDBI  dec_NDMI  dec_BAEI   dec_BSI  \n",
      "0 -0.582977 -0.203604  0.203604  2.284158 -0.151742  \n",
      "1 -0.448827 -0.140714  0.140714  1.457509 -0.098871  \n",
      "2 -0.869244 -0.245951  0.245951  2.616980 -0.185399  \n",
      "3 -0.236880 -0.018406  0.018406  0.789884  0.025922  \n",
      "4 -0.952528 -0.305394  0.305394  1.919225 -0.248522  \n",
      "\n",
      "[5 rows x 313 columns]\n",
      "[1 0 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "bnotes = pd.read_csv('2019_S2_predictors.csv')\n",
    "bnotes = bnotes.drop(['Unnamed: 0', 'class2', 'class5', 'class6', 'class9', 'class10', 'class13', 'class14', 'class17', 'class18', 'class21', 'class22', 'y_coord','x_coord'], axis=1)\n",
    "\n",
    "print(bnotes.head())\n",
    "print(bnotes['class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12797, 313)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnotes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>jan_ca</th>\n",
       "      <th>jan_b</th>\n",
       "      <th>jan_g</th>\n",
       "      <th>jan_r</th>\n",
       "      <th>jan_r1</th>\n",
       "      <th>jan_r2</th>\n",
       "      <th>jan_r3</th>\n",
       "      <th>jan_n</th>\n",
       "      <th>jan_nn</th>\n",
       "      <th>...</th>\n",
       "      <th>dec_TCG_GSO</th>\n",
       "      <th>dec_TCG</th>\n",
       "      <th>dec_LAI</th>\n",
       "      <th>dec_SAVI</th>\n",
       "      <th>dec_MSAVI</th>\n",
       "      <th>dec_BUI</th>\n",
       "      <th>dec_NDBI</th>\n",
       "      <th>dec_NDMI</th>\n",
       "      <th>dec_BAEI</th>\n",
       "      <th>dec_BSI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12797.000000</td>\n",
       "      <td>12797.000000</td>\n",
       "      <td>12797.000000</td>\n",
       "      <td>12797.000000</td>\n",
       "      <td>12797.000000</td>\n",
       "      <td>12797.000000</td>\n",
       "      <td>12797.000000</td>\n",
       "      <td>12797.000000</td>\n",
       "      <td>12797.000000</td>\n",
       "      <td>12797.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12797.000000</td>\n",
       "      <td>12797.000000</td>\n",
       "      <td>12797.000000</td>\n",
       "      <td>12797.000000</td>\n",
       "      <td>12797.000000</td>\n",
       "      <td>12797.000000</td>\n",
       "      <td>12797.000000</td>\n",
       "      <td>12797.000000</td>\n",
       "      <td>12797.000000</td>\n",
       "      <td>12797.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.803704</td>\n",
       "      <td>822.118407</td>\n",
       "      <td>638.117274</td>\n",
       "      <td>631.781863</td>\n",
       "      <td>637.624580</td>\n",
       "      <td>921.765101</td>\n",
       "      <td>1437.895679</td>\n",
       "      <td>1634.711729</td>\n",
       "      <td>1833.712569</td>\n",
       "      <td>1863.929671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.101086</td>\n",
       "      <td>0.052865</td>\n",
       "      <td>0.774201</td>\n",
       "      <td>0.205182</td>\n",
       "      <td>0.177617</td>\n",
       "      <td>-0.617333</td>\n",
       "      <td>-0.170129</td>\n",
       "      <td>0.170129</td>\n",
       "      <td>2.375074</td>\n",
       "      <td>-0.134930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.999588</td>\n",
       "      <td>699.870301</td>\n",
       "      <td>583.899705</td>\n",
       "      <td>511.859025</td>\n",
       "      <td>534.747996</td>\n",
       "      <td>577.787031</td>\n",
       "      <td>605.650197</td>\n",
       "      <td>643.713982</td>\n",
       "      <td>682.038767</td>\n",
       "      <td>703.942369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128884</td>\n",
       "      <td>0.045418</td>\n",
       "      <td>0.397603</td>\n",
       "      <td>0.084729</td>\n",
       "      <td>0.078238</td>\n",
       "      <td>0.348811</td>\n",
       "      <td>0.162565</td>\n",
       "      <td>0.162565</td>\n",
       "      <td>1.821511</td>\n",
       "      <td>0.150920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.657939</td>\n",
       "      <td>-0.518141</td>\n",
       "      <td>-2.331380</td>\n",
       "      <td>-0.137408</td>\n",
       "      <td>-0.139201</td>\n",
       "      <td>-1.617840</td>\n",
       "      <td>-0.876543</td>\n",
       "      <td>-0.433603</td>\n",
       "      <td>0.581521</td>\n",
       "      <td>-0.704497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>603.000000</td>\n",
       "      <td>1136.000000</td>\n",
       "      <td>1319.000000</td>\n",
       "      <td>1497.000000</td>\n",
       "      <td>1520.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127264</td>\n",
       "      <td>0.023448</td>\n",
       "      <td>0.545062</td>\n",
       "      <td>0.144795</td>\n",
       "      <td>0.122939</td>\n",
       "      <td>-0.850075</td>\n",
       "      <td>-0.261681</td>\n",
       "      <td>0.054780</td>\n",
       "      <td>1.449853</td>\n",
       "      <td>-0.215860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>642.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>527.500000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>834.500000</td>\n",
       "      <td>1353.000000</td>\n",
       "      <td>1550.000000</td>\n",
       "      <td>1763.500000</td>\n",
       "      <td>1791.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073674</td>\n",
       "      <td>0.056684</td>\n",
       "      <td>0.756764</td>\n",
       "      <td>0.208185</td>\n",
       "      <td>0.177115</td>\n",
       "      <td>-0.559696</td>\n",
       "      <td>-0.127275</td>\n",
       "      <td>0.127275</td>\n",
       "      <td>1.923391</td>\n",
       "      <td>-0.092744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>822.000000</td>\n",
       "      <td>786.000000</td>\n",
       "      <td>799.250000</td>\n",
       "      <td>1110.000000</td>\n",
       "      <td>1619.500000</td>\n",
       "      <td>1837.000000</td>\n",
       "      <td>2084.000000</td>\n",
       "      <td>2116.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029332</td>\n",
       "      <td>0.081996</td>\n",
       "      <td>0.977760</td>\n",
       "      <td>0.262614</td>\n",
       "      <td>0.228072</td>\n",
       "      <td>-0.350964</td>\n",
       "      <td>-0.054780</td>\n",
       "      <td>0.261681</td>\n",
       "      <td>2.663507</td>\n",
       "      <td>-0.029306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>7964.000000</td>\n",
       "      <td>10696.000000</td>\n",
       "      <td>12132.000000</td>\n",
       "      <td>14788.000000</td>\n",
       "      <td>16075.000000</td>\n",
       "      <td>16062.000000</td>\n",
       "      <td>15971.000000</td>\n",
       "      <td>15856.000000</td>\n",
       "      <td>15811.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073430</td>\n",
       "      <td>0.282090</td>\n",
       "      <td>11.103901</td>\n",
       "      <td>0.553132</td>\n",
       "      <td>0.571734</td>\n",
       "      <td>0.415682</td>\n",
       "      <td>0.433603</td>\n",
       "      <td>0.876543</td>\n",
       "      <td>44.132355</td>\n",
       "      <td>0.359759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 313 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              class        jan_ca         jan_b         jan_g         jan_r  \\\n",
       "count  12797.000000  12797.000000  12797.000000  12797.000000  12797.000000   \n",
       "mean       2.803704    822.118407    638.117274    631.781863    637.624580   \n",
       "std        1.999588    699.870301    583.899705    511.859025    534.747996   \n",
       "min        0.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "25%        0.000000    354.000000    275.000000    340.000000    336.000000   \n",
       "50%        4.000000    642.000000    506.000000    527.500000    548.000000   \n",
       "75%        4.000000   1071.000000    822.000000    786.000000    799.250000   \n",
       "max        6.000000   7964.000000  10696.000000  12132.000000  14788.000000   \n",
       "\n",
       "             jan_r1        jan_r2        jan_r3         jan_n        jan_nn  \\\n",
       "count  12797.000000  12797.000000  12797.000000  12797.000000  12797.000000   \n",
       "mean     921.765101   1437.895679   1634.711729   1833.712569   1863.929671   \n",
       "std      577.787031    605.650197    643.713982    682.038767    703.942369   \n",
       "min        1.000000      1.000000      1.000000      1.000000      4.000000   \n",
       "25%      603.000000   1136.000000   1319.000000   1497.000000   1520.000000   \n",
       "50%      834.500000   1353.000000   1550.000000   1763.500000   1791.000000   \n",
       "75%     1110.000000   1619.500000   1837.000000   2084.000000   2116.000000   \n",
       "max    16075.000000  16062.000000  15971.000000  15856.000000  15811.000000   \n",
       "\n",
       "       ...   dec_TCG_GSO       dec_TCG       dec_LAI      dec_SAVI  \\\n",
       "count  ...  12797.000000  12797.000000  12797.000000  12797.000000   \n",
       "mean   ...     -0.101086      0.052865      0.774201      0.205182   \n",
       "std    ...      0.128884      0.045418      0.397603      0.084729   \n",
       "min    ...     -1.657939     -0.518141     -2.331380     -0.137408   \n",
       "25%    ...     -0.127264      0.023448      0.545062      0.144795   \n",
       "50%    ...     -0.073674      0.056684      0.756764      0.208185   \n",
       "75%    ...     -0.029332      0.081996      0.977760      0.262614   \n",
       "max    ...      0.073430      0.282090     11.103901      0.553132   \n",
       "\n",
       "          dec_MSAVI       dec_BUI      dec_NDBI      dec_NDMI      dec_BAEI  \\\n",
       "count  12797.000000  12797.000000  12797.000000  12797.000000  12797.000000   \n",
       "mean       0.177617     -0.617333     -0.170129      0.170129      2.375074   \n",
       "std        0.078238      0.348811      0.162565      0.162565      1.821511   \n",
       "min       -0.139201     -1.617840     -0.876543     -0.433603      0.581521   \n",
       "25%        0.122939     -0.850075     -0.261681      0.054780      1.449853   \n",
       "50%        0.177115     -0.559696     -0.127275      0.127275      1.923391   \n",
       "75%        0.228072     -0.350964     -0.054780      0.261681      2.663507   \n",
       "max        0.571734      0.415682      0.433603      0.876543     44.132355   \n",
       "\n",
       "            dec_BSI  \n",
       "count  12797.000000  \n",
       "mean      -0.134930  \n",
       "std        0.150920  \n",
       "min       -0.704497  \n",
       "25%       -0.215860  \n",
       "50%       -0.092744  \n",
       "75%       -0.029306  \n",
       "max        0.359759  \n",
       "\n",
       "[8 rows x 313 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnotes.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = '2019_S2_predictors.csv'\n",
    "df = pd.read_table(training_data, sep=',')\n",
    "# clear residuals\n",
    "# for non balanced classification\n",
    "df = df.drop(['Unnamed: 0', 'class2', 'class5', 'class6', 'class9', 'class10', 'class13', 'class14', 'class17', 'class18', 'class21', 'class22', 'y_coord','x_coord'], axis=1)\n",
    "# for balanced classification\n",
    "#df = df.drop(['Unnamed: 0', 'class2', 'class5', 'class6', 'class9', 'class10', 'class13', 'class14', 'class17', 'class18', 'class21', 'class22'], axis=1)\n",
    "#df = df.drop('fid', axis=1)\n",
    "\n",
    "model_variables = df.drop('class', axis=1).columns.values.tolist()\n",
    "column_names = model_variables\n",
    "y = df['class']\n",
    "X = df.drop('class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jan_ca</th>\n",
       "      <th>jan_b</th>\n",
       "      <th>jan_g</th>\n",
       "      <th>jan_r</th>\n",
       "      <th>jan_r1</th>\n",
       "      <th>jan_r2</th>\n",
       "      <th>jan_r3</th>\n",
       "      <th>jan_n</th>\n",
       "      <th>jan_nn</th>\n",
       "      <th>jan_wv</th>\n",
       "      <th>...</th>\n",
       "      <th>dec_TCG_GSO</th>\n",
       "      <th>dec_TCG</th>\n",
       "      <th>dec_LAI</th>\n",
       "      <th>dec_SAVI</th>\n",
       "      <th>dec_MSAVI</th>\n",
       "      <th>dec_BUI</th>\n",
       "      <th>dec_NDBI</th>\n",
       "      <th>dec_NDMI</th>\n",
       "      <th>dec_BAEI</th>\n",
       "      <th>dec_BSI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.00</td>\n",
       "      <td>56.50</td>\n",
       "      <td>122.5</td>\n",
       "      <td>211.0</td>\n",
       "      <td>444.00</td>\n",
       "      <td>1253.5</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>1678.00</td>\n",
       "      <td>1815.5</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059647</td>\n",
       "      <td>0.045820</td>\n",
       "      <td>0.717313</td>\n",
       "      <td>0.186339</td>\n",
       "      <td>0.153891</td>\n",
       "      <td>-0.582977</td>\n",
       "      <td>-0.203604</td>\n",
       "      <td>0.203604</td>\n",
       "      <td>2.284158</td>\n",
       "      <td>-0.151742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>303.00</td>\n",
       "      <td>368.25</td>\n",
       "      <td>357.5</td>\n",
       "      <td>374.0</td>\n",
       "      <td>717.00</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>1308.0</td>\n",
       "      <td>1699.00</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1649.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109955</td>\n",
       "      <td>0.047009</td>\n",
       "      <td>0.809818</td>\n",
       "      <td>0.187611</td>\n",
       "      <td>0.164786</td>\n",
       "      <td>-0.448827</td>\n",
       "      <td>-0.140714</td>\n",
       "      <td>0.140714</td>\n",
       "      <td>1.457509</td>\n",
       "      <td>-0.098871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>511.25</td>\n",
       "      <td>252.50</td>\n",
       "      <td>254.5</td>\n",
       "      <td>388.0</td>\n",
       "      <td>643.25</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>1309.0</td>\n",
       "      <td>1688.00</td>\n",
       "      <td>1639.0</td>\n",
       "      <td>2230.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025636</td>\n",
       "      <td>0.084585</td>\n",
       "      <td>0.827439</td>\n",
       "      <td>0.256545</td>\n",
       "      <td>0.216626</td>\n",
       "      <td>-0.869244</td>\n",
       "      <td>-0.245951</td>\n",
       "      <td>0.245951</td>\n",
       "      <td>2.616980</td>\n",
       "      <td>-0.185399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.50</td>\n",
       "      <td>51.00</td>\n",
       "      <td>102.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>358.00</td>\n",
       "      <td>1221.0</td>\n",
       "      <td>1525.0</td>\n",
       "      <td>1795.50</td>\n",
       "      <td>1813.0</td>\n",
       "      <td>1894.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.438328</td>\n",
       "      <td>0.039137</td>\n",
       "      <td>1.154730</td>\n",
       "      <td>0.222647</td>\n",
       "      <td>0.216470</td>\n",
       "      <td>-0.236880</td>\n",
       "      <td>-0.018406</td>\n",
       "      <td>0.018406</td>\n",
       "      <td>0.789884</td>\n",
       "      <td>0.025922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>279.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>258.0</td>\n",
       "      <td>274.5</td>\n",
       "      <td>507.00</td>\n",
       "      <td>1258.0</td>\n",
       "      <td>1524.0</td>\n",
       "      <td>1668.25</td>\n",
       "      <td>1761.0</td>\n",
       "      <td>1874.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029993</td>\n",
       "      <td>0.134382</td>\n",
       "      <td>1.425100</td>\n",
       "      <td>0.365924</td>\n",
       "      <td>0.339766</td>\n",
       "      <td>-0.952528</td>\n",
       "      <td>-0.305394</td>\n",
       "      <td>0.305394</td>\n",
       "      <td>1.919225</td>\n",
       "      <td>-0.248522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12792</th>\n",
       "      <td>140.00</td>\n",
       "      <td>198.00</td>\n",
       "      <td>321.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>613.00</td>\n",
       "      <td>1376.0</td>\n",
       "      <td>1570.0</td>\n",
       "      <td>1852.00</td>\n",
       "      <td>1853.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010064</td>\n",
       "      <td>0.096308</td>\n",
       "      <td>0.958723</td>\n",
       "      <td>0.296436</td>\n",
       "      <td>0.253684</td>\n",
       "      <td>-1.041837</td>\n",
       "      <td>-0.296599</td>\n",
       "      <td>0.296599</td>\n",
       "      <td>2.827416</td>\n",
       "      <td>-0.244999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12793</th>\n",
       "      <td>575.50</td>\n",
       "      <td>608.50</td>\n",
       "      <td>446.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>635.50</td>\n",
       "      <td>1220.5</td>\n",
       "      <td>1306.0</td>\n",
       "      <td>1720.00</td>\n",
       "      <td>1463.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.148923</td>\n",
       "      <td>0.027291</td>\n",
       "      <td>0.797694</td>\n",
       "      <td>0.161353</td>\n",
       "      <td>0.143223</td>\n",
       "      <td>-0.415802</td>\n",
       "      <td>-0.162687</td>\n",
       "      <td>0.162687</td>\n",
       "      <td>1.385545</td>\n",
       "      <td>-0.109597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12794</th>\n",
       "      <td>64.00</td>\n",
       "      <td>433.00</td>\n",
       "      <td>580.0</td>\n",
       "      <td>752.0</td>\n",
       "      <td>995.00</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>1504.00</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>1672.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058570</td>\n",
       "      <td>0.033750</td>\n",
       "      <td>0.406939</td>\n",
       "      <td>0.144411</td>\n",
       "      <td>0.113540</td>\n",
       "      <td>-0.475634</td>\n",
       "      <td>-0.040483</td>\n",
       "      <td>0.040483</td>\n",
       "      <td>2.348404</td>\n",
       "      <td>-0.034799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12795</th>\n",
       "      <td>465.00</td>\n",
       "      <td>477.00</td>\n",
       "      <td>554.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>836.00</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>1147.0</td>\n",
       "      <td>1322.00</td>\n",
       "      <td>1388.0</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.091083</td>\n",
       "      <td>0.032056</td>\n",
       "      <td>0.408460</td>\n",
       "      <td>0.139940</td>\n",
       "      <td>0.111585</td>\n",
       "      <td>-0.304417</td>\n",
       "      <td>0.062159</td>\n",
       "      <td>-0.062159</td>\n",
       "      <td>2.008159</td>\n",
       "      <td>0.080313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12796</th>\n",
       "      <td>702.00</td>\n",
       "      <td>906.00</td>\n",
       "      <td>906.5</td>\n",
       "      <td>996.0</td>\n",
       "      <td>1246.00</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>2355.00</td>\n",
       "      <td>2171.0</td>\n",
       "      <td>2417.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046931</td>\n",
       "      <td>0.109849</td>\n",
       "      <td>1.130121</td>\n",
       "      <td>0.308548</td>\n",
       "      <td>0.277469</td>\n",
       "      <td>-0.813364</td>\n",
       "      <td>-0.241895</td>\n",
       "      <td>0.241895</td>\n",
       "      <td>1.874261</td>\n",
       "      <td>-0.161439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12797 rows × 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       jan_ca   jan_b  jan_g  jan_r   jan_r1  jan_r2  jan_r3    jan_n  jan_nn  \\\n",
       "0        2.00   56.50  122.5  211.0   444.00  1253.5  1462.0  1678.00  1815.5   \n",
       "1      303.00  368.25  357.5  374.0   717.00  1101.0  1308.0  1699.00  1700.0   \n",
       "2      511.25  252.50  254.5  388.0   643.25  1104.0  1309.0  1688.00  1639.0   \n",
       "3       53.50   51.00  102.0  117.0   358.00  1221.0  1525.0  1795.50  1813.0   \n",
       "4      279.00  180.00  258.0  274.5   507.00  1258.0  1524.0  1668.25  1761.0   \n",
       "...       ...     ...    ...    ...      ...     ...     ...      ...     ...   \n",
       "12792  140.00  198.00  321.0  284.0   613.00  1376.0  1570.0  1852.00  1853.0   \n",
       "12793  575.50  608.50  446.0  448.0   635.50  1220.5  1306.0  1720.00  1463.0   \n",
       "12794   64.00  433.00  580.0  752.0   995.00  1294.0  1299.0  1504.00  1508.0   \n",
       "12795  465.00  477.00  554.0  705.0   836.00  1073.0  1147.0  1322.00  1388.0   \n",
       "12796  702.00  906.00  906.5  996.0  1246.00  1790.0  1915.0  2355.00  2171.0   \n",
       "\n",
       "       jan_wv  ...  dec_TCG_GSO   dec_TCG   dec_LAI  dec_SAVI  dec_MSAVI  \\\n",
       "0      2021.0  ...    -0.059647  0.045820  0.717313  0.186339   0.153891   \n",
       "1      1649.0  ...    -0.109955  0.047009  0.809818  0.187611   0.164786   \n",
       "2      2230.0  ...    -0.025636  0.084585  0.827439  0.256545   0.216626   \n",
       "3      1894.5  ...    -0.438328  0.039137  1.154730  0.222647   0.216470   \n",
       "4      1874.0  ...    -0.029993  0.134382  1.425100  0.365924   0.339766   \n",
       "...       ...  ...          ...       ...       ...       ...        ...   \n",
       "12792  1800.0  ...    -0.010064  0.096308  0.958723  0.296436   0.253684   \n",
       "12793  1430.0  ...    -0.148923  0.027291  0.797694  0.161353   0.143223   \n",
       "12794  1672.0  ...    -0.058570  0.033750  0.406939  0.144411   0.113540   \n",
       "12795  1961.0  ...    -0.091083  0.032056  0.408460  0.139940   0.111585   \n",
       "12796  2417.0  ...    -0.046931  0.109849  1.130121  0.308548   0.277469   \n",
       "\n",
       "        dec_BUI  dec_NDBI  dec_NDMI  dec_BAEI   dec_BSI  \n",
       "0     -0.582977 -0.203604  0.203604  2.284158 -0.151742  \n",
       "1     -0.448827 -0.140714  0.140714  1.457509 -0.098871  \n",
       "2     -0.869244 -0.245951  0.245951  2.616980 -0.185399  \n",
       "3     -0.236880 -0.018406  0.018406  0.789884  0.025922  \n",
       "4     -0.952528 -0.305394  0.305394  1.919225 -0.248522  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "12792 -1.041837 -0.296599  0.296599  2.827416 -0.244999  \n",
       "12793 -0.415802 -0.162687  0.162687  1.385545 -0.109597  \n",
       "12794 -0.475634 -0.040483  0.040483  2.348404 -0.034799  \n",
       "12795 -0.304417  0.062159 -0.062159  2.008159  0.080313  \n",
       "12796 -0.813364 -0.241895  0.241895  1.874261 -0.161439  \n",
       "\n",
       "[12797 rows x 312 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting to training and testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8957, 312)\n",
      "(3840,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3)\n",
    "print(X_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized input X train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Import the MLP classifier model from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(200, 150, 100, 50), max_iter=500,\n",
       "              random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(200, 150, 100, 50), max_iter=500,\n",
       "              random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(200, 150, 100, 50), max_iter=500,\n",
       "              random_state=42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(200,150,100,50),max_iter=500, \n",
    "                    activation='relu',random_state=42, solver='adam')\n",
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_estimators=1000, n_jobs=30,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_estimators=1000, n_jobs=30,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', n_estimators=1000, n_jobs=30,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = RandomForestClassifier(n_estimators=1000,n_jobs=30,random_state=42,class_weight='balanced')\n",
    "mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### About parameters \n",
    "\n",
    "1. hidden_layer_sizes : tuple, length = n_layers - 2, default (100,)\n",
    "\n",
    "The ith element represents the number of neurons in the ith hidden layer.\n",
    "\n",
    "2. activation : {‘identity’, ‘logistic’, ‘tanh’, ‘relu’}, default ‘relu’\n",
    "\n",
    "Activation function for the hidden layer.\n",
    "\n",
    "‘identity’, no-op activation, useful to implement linear bottleneck, returns f(x) = x\n",
    "‘logistic’, the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).\n",
    "‘tanh’, the hyperbolic tan function, returns f(x) = tanh(x).\n",
    "‘relu’, the rectified linear unit function, returns f(x) = max(0, x)\n",
    "\n",
    "3. learning_rate : {‘constant’, ‘invscaling’, ‘adaptive’}, default ‘constant’\n",
    "\n",
    "4. learning_rate_init : double, optional, default 0.001\n",
    "\n",
    "5. max_iter : int, optional, default 200\n",
    "\n",
    "Maximum number of iterations. The solver iterates until convergence (determined by ‘tol’) or this number of iterations. For stochastic solvers (‘sgd’, ‘adam’), note that this determines the number of epochs (how many times each data point will be used), not the number of gradient steps.\n",
    "\n",
    "6. shuffle : bool, optional, default True\n",
    "\n",
    "Whether to shuffle samples in each iteration. Only used when solver=’sgd’ or ‘adam’.\n",
    "\n",
    "7. momentum : float, default 0.9\n",
    "\n",
    "Momentum for gradient descent update. Should be between 0 and 1. Only used when solver=’sgd’.\n",
    "\n",
    "8. early_stopping : bool, default False\n",
    "\n",
    "Whether to use early stopping to terminate training when validation score is not improving. If set to true, it will automatically keep 10% of training data as validation and terminate training when validation score is not improving by at least tol for two consecutive epochs. Only effective when solver=’sgd’ or ‘adam’\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9h 59min 1s, sys: 9h 35min 59s, total: 19h 35min\n",
      "Wall time: 29min 25s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(200, 150, 100, 50), max_iter=500,\n",
       "              random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(200, 150, 100, 50), max_iter=500,\n",
       "              random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(200, 150, 100, 50), max_iter=500,\n",
       "              random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 56s, sys: 0 ns, total: 3min 56s\n",
      "Wall time: 9.21 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_estimators=1000, n_jobs=30,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_estimators=1000, n_jobs=30,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', n_estimators=1000, n_jobs=30,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 0, ..., 4, 4, 4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = mlp.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics- Confusion matrix and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1152,    0,    5,    0,   73,    1,    1],\n",
       "       [  11,    0,    0,    0,   19,    0,    0],\n",
       "       [  60,    0,   15,    0,    8,    0,    0],\n",
       "       [  15,    0,    0,    5,    8,    0,    0],\n",
       "       [ 130,    0,    0,    1, 1819,   31,    2],\n",
       "       [  12,    0,    0,    0,  146,  229,    0],\n",
       "       [  14,    0,    0,    0,   51,    4,   28]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84      1232\n",
      "           1       0.00      0.00      0.00        30\n",
      "           2       0.14      0.12      0.13        83\n",
      "           3       0.00      0.00      0.00        28\n",
      "           4       0.80      0.89      0.84      1983\n",
      "           5       0.60      0.32      0.41       387\n",
      "           6       0.29      0.02      0.04        97\n",
      "\n",
      "    accuracy                           0.77      3840\n",
      "   macro avg       0.38      0.32      0.32      3840\n",
      "weighted avg       0.74      0.77      0.75      3840\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebastian_foertsch/datacube/jupyterhub/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sebastian_foertsch/datacube/jupyterhub/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sebastian_foertsch/datacube/jupyterhub/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      1232\n",
      "           1       0.00      0.00      0.00        30\n",
      "           2       0.75      0.18      0.29        83\n",
      "           3       0.83      0.18      0.29        28\n",
      "           4       0.86      0.92      0.89      1983\n",
      "           5       0.86      0.59      0.70       387\n",
      "           6       0.90      0.29      0.44        97\n",
      "\n",
      "    accuracy                           0.85      3840\n",
      "   macro avg       0.72      0.44      0.50      3840\n",
      "weighted avg       0.84      0.85      0.83      3840\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebastian_foertsch/datacube/jupyterhub/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sebastian_foertsch/datacube/jupyterhub/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sebastian_foertsch/datacube/jupyterhub/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
